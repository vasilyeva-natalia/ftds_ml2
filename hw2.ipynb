{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 1.10.2021\n",
    "\n",
    "Мягкий дедлайн: 17.10.2021 23:59 МСК\n",
    "\n",
    "Жесткий дедлайн: 31.10.2021 23:59 МСК (1 неделя -- минус балл)\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Загрузите решение в свой репозиторий на github и поделитесь [ссылкой на решение в форме](https://forms.gle/ZzCaqRj6bmfpSpyL7). Не забудьте дать доступ к Вашему репозиторию, что у преподавателей была возмоожность проверить работу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CFH8ZZ2PASkz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import lightgbm as lgbm\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, sample_size=0.5, classifier='logreg', hyper_params={}):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "\n",
    "        sample_size, float: sample percentage to draw samples for computing sigma.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        hyper_params, dict: classifier's hyperparams.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.sample_size = sample_size\n",
    "        self.classifier = classifier\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "            \n",
    "        self.new_dim = X.shape[1]\n",
    "        X_sample = X[np.random.randint(X.shape[0], size=int(np.ceil(X.shape[0] * self.sample_size))), :]\n",
    "        self.sigma_sq = np.median(pdist(X_sample, metric='sqeuclidean'))\n",
    "        \n",
    "#         self.w = np.random.normal(loc=0, scale=1/np.sqrt(self.sigma), size=self.n_features)\n",
    "        self.w = np.zeros(shape=(self.n_features, self.new_dim))\n",
    "\n",
    "        for n in range(self.n_features):\n",
    "#             self.w[n, :] = multivariate_normal.rvs(cov=np.eye(self.new_dim) * (1/sigma_sq))\n",
    "#             Генерируем вес независимо для каждой фичи\n",
    "            self.w[n, :] = np.random.normal(loc=0, scale=1/np.sqrt(self.sigma_sq), size=self.new_dim)\n",
    "        \n",
    "        self.b = np.random.uniform(low=-np.pi, high=np.pi, size=self.n_features)\n",
    "        fi = np.cos(self.w @ X.T + self.b.reshape(self.n_features, -1)).T\n",
    "        \n",
    "        if self.classifier=='logreg':\n",
    "            self.clf = LogisticRegression(**self.hyper_params)\n",
    "        elif self.classifier=='svm':\n",
    "            self.clf = LinearSVC(**self.hyper_params)\n",
    "        self.clf.fit(fi, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        fi_pred = np.cos((self.w @ X.T) + self.b.reshape(self.n_features, -1)).T\n",
    "        pred = self.clf.predict_proba(fi_pred)\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        fi_pred = np.cos((self.w @ X.T) + self.b.reshape(self.n_features, -1)).T\n",
    "        pred = self.clf.predict(fi_pred)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddG059AKASlJ",
    "outputId": "6cafa411-7ede-4301-9890-f9590be58cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест на данных Fashion MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на тесте: 0.8787\n"
     ]
    }
   ],
   "source": [
    "# Не сходится с маленьким числом max_iter, а с увеличением числа итераций - долго обучается.\n",
    "print('Тест на данных Fashion MNIST')\n",
    "rff = RFFPipeline(hyper_params={'max_iter': 500})\n",
    "rff.fit(x_train, y_train)\n",
    "rff_pred_test = rff.predict(x_test)\n",
    "ac = accuracy_score(y_test, rff_pred_test)\n",
    "assert ac >= 0.84, 'Доля верных ответов ниже 0.84 :('\n",
    "print('Доля верных ответов на тесте: {}'.format(ac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9ePLQVHASlL"
   },
   "outputs": [],
   "source": [
    "# Размерность в новом пространстве для PCA по дефолту 50 (вынесем параметр для использования в градиентном бустинге)\n",
    "new_dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qmXfEe2JASlM",
    "outputId": "286a8f47-ccf1-4095-e2f0-a0de2a806f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM\n",
      "RFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear SVM': LinearSVC(max_iter=2000, random_state=100),\n",
    "    'Kernel SVM': SVC(kernel='rbf', random_state=100),\n",
    "    'RFF': RFFPipeline(new_dim=new_dim, use_PCA=True, classifier='logreg', hyper_params={'max_iter': 2000}),\n",
    "}\n",
    "\n",
    "accuracy = {}\n",
    "times = {}\n",
    "\n",
    "# Возьмем половину выборки для обучения - все алгоритмы обучаются слишком долго\n",
    "mask = np.random.randint(x_train.shape[0], size=int(np.ceil(x_train.shape[0] * 0.5)))\n",
    "x_train_ = x_train[mask, :]\n",
    "y_train_ = y_train[mask]\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    clf = model\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(x_train_, y_train_)\n",
    "    # clf.fit(x_train, y_train)\n",
    "\n",
    "    end = time.time()\n",
    "    pred_test = clf.predict(x_test)\n",
    "    \n",
    "    accuracy[name] = accuracy_score(y_test, pred_test)\n",
    "    times[name] = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tz7FYQdHASlN"
   },
   "outputs": [],
   "source": [
    "# Для градиентного бустинга подбираем гиперпараметры.\n",
    "pca = PCA(n_components=new_dim)\n",
    "X_train = pca.fit_transform(x_train)\n",
    "X_test = pca.transform(x_test)\n",
    "\n",
    "hp_grid = {\n",
    "    'max_depth': np.arange(2, 10),\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': np.linspace(0.01, 10, 100)\n",
    "}\n",
    "\n",
    "gb = lgbm.LGBMClassifier(objective='multiclass')\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "# start = time.time()\n",
    "rsearch = RandomizedSearchCV(gb, hp_grid, cv=skf, random_state=100)\n",
    "rsearch.fit(X_train, y_train)\n",
    "best_params = rsearch.best_params_\n",
    "best_params['objective'] = 'multiclass'\n",
    "\n",
    "gb_clf = lgbm.LGBMClassifier(**best_params)\n",
    "start = time.time()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "gb_pred_test = gb_clf.predict(X_test)\n",
    "\n",
    "accuracy['LGBM with PCA'] = accuracy_score(y_test, gb_pred_test)\n",
    "times['LGBM with PCA'] = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4fH8WzWASlP"
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame.from_dict(accuracy, orient='index', columns=['Accuracy'])\n",
    "time_ = pd.DataFrame.from_dict(times, orient='index', columns=['Time'])\n",
    "results = scores.join(time_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "WQkjMT0qASlQ",
    "outputId": "4cd1c313-e1f6-4cc0-eeba-152e0fd8cc0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Kernel SVM</th>\n",
       "      <th>RFF</th>\n",
       "      <th>LGBM with PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.870600</td>\n",
       "      <td>0.868700</td>\n",
       "      <td>0.876700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>261.858239</td>\n",
       "      <td>166.233782</td>\n",
       "      <td>419.237202</td>\n",
       "      <td>99.794426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Linear SVM  Kernel SVM         RFF  LGBM with PCA\n",
       "Accuracy    0.733500    0.870600    0.868700       0.876700\n",
       "Time      261.858239  166.233782  419.237202      99.794426"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJmy1o8lASlR"
   },
   "source": [
    "Самое высокое качество показывает градиентный бустинг, самое низкое - линейный SVM, что логично, т.к. он распознает только линейные зависимости в данных. Сопоставимым, достаточно высоким качеством с лучшим алгоритмом обладают ядровой SVM и подход со случайными признаками, т.к. данные алгоритмы также улавливают нелинейности с помощью преобразования исходных признаков в нелинейные и перехода таким образом в спрямляющее пространство, где уже можно разделить данные с помощью линейного алгоритма. Также следует отметить, что реализации RFFPipeline и ядровой SVM из sklearn обладают схожим качеством (т.к. в RFFPipeline по сути и приближаем ядро с помощью случайных признаков Фурье). По времени наилучшая реализация у алгоритма LGBM (без учета перебора гиперпараметров), а медленнее всего работает данная реализация подхода со случайными признаками Фурье (RFFPipeline). С учетом перебора ГП градиентый бустинг работал бы дольше.\n",
    "\n",
    "Таким образом, алгоритм со случайными признаками довольно мощный: распознает нелинейные зависимости практически как градиентный бустинг, однако работает довольно долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qY9RtY8WASlS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_DI9qWlASlU"
   },
   "outputs": [],
   "source": [
    "def train_rff_hp(param_name, param_list):\n",
    "    accuracy = []\n",
    "    times = []\n",
    "    \n",
    "    for hp in param_list:\n",
    "        param_dict = {}\n",
    "        param_dict[param_name] = hp\n",
    "        param_dict['hyper_params'] = {'max_iter': 2000}\n",
    "        clf = RFFPipeline(**param_dict)\n",
    "\n",
    "        start = time.time()\n",
    "        clf.fit(x_train_, y_train_)\n",
    "        end = time.time()\n",
    "\n",
    "        pred_test = clf.predict(x_test)\n",
    "        accuracy.append(accuracy_score(y_test, pred_test))\n",
    "        times.append(end - start)\n",
    "        \n",
    "    return accuracy, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "943FTiKZASlU",
    "outputId": "88e4e125-63c0-4a61-9b0d-c41e57ac47b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "use_pca = [True, False]\n",
    "n_features = [1, 10, 100, 500, 700, 1000, 2000, 5000]\n",
    "classifier = ['logreg', 'svm']\n",
    "\n",
    "index_names = ['Accuracy', 'Time']\n",
    "\n",
    "ac_pca, time_pca = train_rff_hp('use_PCA', use_pca)\n",
    "res_pca = pd.DataFrame([ac_pca, time_pca], columns=['With PCA', 'Without PCA'])\n",
    "res_pca.index = index_names\n",
    "\n",
    "ac_nfeat, time_nfeat = train_rff_hp('n_features', n_features)\n",
    "res_nfeat = pd.DataFrame([ac_nfeat, time_nfeat], columns=n_features)\n",
    "res_nfeat.index = index_names\n",
    "\n",
    "ac_clf, time_clf = train_rff_hp('classifier', classifier)\n",
    "res_clf = pd.DataFrame([ac_clf, time_clf], columns=classifier)\n",
    "res_clf.index = index_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amMvOxU4ASlV"
   },
   "source": [
    "1. **Предварительное понижение размерности с помощью PCA** помогает: на данных признаках улучшает качество алгоритма и плюс сокращает время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4foXVFDASlW",
    "outputId": "5f1d794e-30f1-4cfa-b354-11777ff0d1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with PCA 0.8705, without PCA 0.8448\n",
      "Time of learning with PCA 418.4051, without PCA 474.3505\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy with PCA {}, without PCA {}'.format(ac_pca[0], ac_pca[1]))\n",
    "print('Time of learning with PCA {}, without PCA {}'.format(round(time_pca[0], 4), round(time_pca[1], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "uwZ88bOuASlX",
    "outputId": "8821c3f9-fb39-4637-8fa5-d6f339311361"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>With PCA</th>\n",
       "      <th>Without PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.870500</td>\n",
       "      <td>0.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>418.405087</td>\n",
       "      <td>474.350499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            With PCA  Without PCA\n",
       "Accuracy    0.870500     0.844800\n",
       "Time      418.405087   474.350499"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVS6UyXCASlY"
   },
   "source": [
    "2. Качество алгоритма растет с **количеством новых синтетических признаков n_features** и в определенный момент выходит на плато (начиная ~ с 1000 новых признаков), но при этом время обучения алгоритма растет линейно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "jrzlRccgT9rU",
    "outputId": "46a093cd-2d32-4304-f24f-01843f3373b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>500</th>\n",
       "      <th>700</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "      <th>5000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.65950</td>\n",
       "      <td>0.838100</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>0.868600</td>\n",
       "      <td>0.870100</td>\n",
       "      <td>0.87140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>7.162586</td>\n",
       "      <td>12.70294</td>\n",
       "      <td>71.923322</td>\n",
       "      <td>185.35788</td>\n",
       "      <td>239.458019</td>\n",
       "      <td>422.199261</td>\n",
       "      <td>656.026211</td>\n",
       "      <td>1369.72251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         10         100   ...        1000        2000        5000\n",
       "Accuracy  0.199100   0.65950   0.838100  ...    0.868600    0.870100     0.87140\n",
       "Time      7.162586  12.70294  71.923322  ...  422.199261  656.026211  1369.72251\n",
       "\n",
       "[2 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_nfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "dHprHYQtUBkG",
    "outputId": "38cb6ad0-cee7-4682-d25d-f5394bc52f2e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(7, 10))\n",
    "ax1.set_title('Accuracy', weight='bold')\n",
    "ax1.plot(n_features, ac_nfeat, marker='.')\n",
    "ax1.grid()\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('N features')\n",
    "\n",
    "ax2.set_title('Time of learning', weight='bold')\n",
    "ax2.plot(n_features, time_nfeat, marker='.')\n",
    "ax2.grid()\n",
    "ax2.set_ylabel('Time')\n",
    "ax2.set_xlabel('N features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFfg5zKIASla"
   },
   "source": [
    "3. Кажется, что обе линейные модели над новыми признаками работают приблизительно одинаково: **logreg и svm** имеют сопоставимое качество, т.к. фактически оба алгоритма строят линейную разделяющую функцию над признаками в новом пространстве. Но можно сказать, что у логистической регрессии немного выше доля верных ответов и обучается она медленее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "8smMVxCxASlb",
    "outputId": "d8c02aff-6873-411f-f613-dee3ad448e41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.871200</td>\n",
       "      <td>0.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>416.402739</td>\n",
       "      <td>254.555294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              logreg         svm\n",
       "Accuracy    0.871200    0.865700\n",
       "Time      416.402739  254.555294"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class RFFPipelineFunction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', sample_size=0.5,\n",
    "                 hyper_params={}, kern_function=np.cos, add_bias_after=False, choose_hp_lgb=True):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: 'svm', 'logreg' or 'lgbm' classification model to use on top of pipeline.\n",
    "        \n",
    "        hyper_params, dict: classifier's hyperparameters.\n",
    "        \n",
    "        kern_function, callable function for matrices: function for generating new features (numpy functions).\n",
    "\n",
    "        add_bias_after, bool: whether to add bias after applying kern_function (outside kern_function)\n",
    "        or before applying function (inside kern_function).\n",
    "\n",
    "        choose_hp_lgb, bool: whether to choose hyperparameters for LightGBM classifier.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.sample_size = sample_size\n",
    "        self.classifier = classifier\n",
    "        self.hyper_params = hyper_params\n",
    "        self.kern_function = kern_function\n",
    "        self.add_bias_after = add_bias_after\n",
    "        self.choose_hp_lgb = choose_hp_lgb\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "            \n",
    "        self.new_dim = X.shape[1]\n",
    "        X_sample = X[np.random.randint(X.shape[0], size=int(np.ceil(X.shape[0] * self.sample_size))), :]\n",
    "        self.sigma_sq = np.median(pdist(X_sample, metric='sqeuclidean'))\n",
    "        \n",
    "        self.w = np.zeros(shape=(self.n_features, self.new_dim))\n",
    "\n",
    "        for n in range(self.n_features):\n",
    "#             self.w[n, :] = multivariate_normal.rvs(cov=np.eye(self.new_dim) * (1/sigma_sq))\n",
    "            self.w[n, :] = np.random.normal(loc=0, scale=1/np.sqrt(self.sigma_sq), size=self.new_dim)\n",
    "        \n",
    "        self.b = np.random.uniform(low=-np.pi, high=np.pi, size=self.n_features)\n",
    "        \n",
    "        if self.add_bias_after:\n",
    "            fi = (self.kern_function(self.w @ X.T) + self.b.reshape(self.n_features, -1)).T\n",
    "        else:\n",
    "            fi = self.kern_function(self.w @ X.T + self.b.reshape(self.n_features, -1)).T\n",
    "        \n",
    "        if self.classifier=='logreg':\n",
    "            self.clf = LogisticRegression(**self.hyper_params)\n",
    "        elif self.classifier=='svm':\n",
    "            self.clf = LinearSVC(**self.hyper_params)\n",
    "        elif self.classifier=='lgbm':\n",
    "            \n",
    "            if self.choose_hp_lgb:\n",
    "                hp_grid = {\n",
    "                    'max_depth': np.arange(2, 10),\n",
    "                    'n_estimators': [50, 100, 200, 300, 500],\n",
    "                    'learning_rate': np.linspace(0.01, 10, 100)\n",
    "                }\n",
    "\n",
    "                gb = lgbm.LGBMClassifier(**self.hyper_params)\n",
    "                skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "                rsearch = RandomizedSearchCV(gb, hp_grid, cv=skf, random_state=100)\n",
    "                rsearch.fit(X_train, y_train)\n",
    "                self.hyper_params = rsearch.best_params_\n",
    "                self.hyper_params['objective'] = 'multiclass'\n",
    "\n",
    "            self.clf = lgbm.LGBMClassifier(**self.hyper_params)\n",
    "\n",
    "        self.clf.fit(fi, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "            \n",
    "        if self.add_bias_after:\n",
    "            fi_pred = (self.kern_function(self.w @ X.T) + self.b.reshape(self.n_features, -1)).T\n",
    "        else:\n",
    "            fi_pred = self.kern_function(self.w @ X.T + self.b.reshape(self.n_features, -1)).T\n",
    "        \n",
    "        pred = self.clf.predict_proba(fi_pred)\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        if self.add_bias_after:\n",
    "            fi_pred = (self.kern_function(self.w @ X.T) + self.b.reshape(self.n_features, -1)).T\n",
    "        else:\n",
    "            fi_pred = self.kern_function(self.w @ X.T + self.b.reshape(self.n_features, -1)).T\n",
    "        pred = self.clf.predict(fi_pred)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "9Neic9f7ASlj"
   },
   "outputs": [],
   "source": [
    "# Обучим с помощью градиентного бустинга и добавим к предыдущим результатам с логрегом и svm.\n",
    "\n",
    "rff_lgb = RFFPipelineFunction(\n",
    "    new_dim=new_dim, use_PCA=True, classifier='lgbm',\n",
    "    hyper_params={'objective': 'multiclass'}, choose_hp_lgb=True\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "rff_lgb.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "pred_test = clf.predict(x_test)\n",
    "ac_lgb = accuracy_score(y_test, pred_test)\n",
    "time_lgb = end - start\n",
    "res_clf['lgbm'] = [ac_lgb, time_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "bJ1UQijGASlk",
    "outputId": "da5e4b05-8335-40e9-b122-9db7b779f53e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg</th>\n",
       "      <th>svm</th>\n",
       "      <th>lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.871200</td>\n",
       "      <td>0.865700</td>\n",
       "      <td>0.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>416.402739</td>\n",
       "      <td>254.555294</td>\n",
       "      <td>3064.731196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              logreg         svm         lgbm\n",
       "Accuracy    0.871200    0.865700     0.868700\n",
       "Time      416.402739  254.555294  3064.731196"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYpX0IxJASlk"
   },
   "source": [
    "С использованием градиентного бустинга в качестве классификатора над полученными случайными признаками Фурье качество модели практически не изменилось по сравнению с линейными классификаторами, но значительно увеличилось время обучения (также за счет подбора гиперпараметров). Получилось, что логистическая регрессия даже немного лучше разделила признаки, чем бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5JTeer4tASll"
   },
   "outputs": [],
   "source": [
    "# В качестве других признаков используем синус, экспоненту и знак от полученных признаков.\n",
    "# И также попробуем добавлять смещение не только внутри этих функций, но и после их применения.\n",
    "functions = [np.cos, np.sin, np.exp, np.sign]\n",
    "add_bias_after = [True, False]\n",
    "diff_functions = [i for i in product(functions, add_bias_after)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mGUaR0IyASll"
   },
   "outputs": [],
   "source": [
    "mask = np.random.randint(x_train.shape[0], size=int(np.ceil(x_train.shape[0] * 0.5)))\n",
    "x_train_ = x_train[mask, :]\n",
    "y_train_ = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHilH7iDASlm",
    "outputId": "87a9a522-75da-4cdc-c820-1fc2982a3570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [26:35<00:00, 199.48s/it]\n"
     ]
    }
   ],
   "source": [
    "ac_func = []\n",
    "time_func = []\n",
    "\n",
    "for hp in tqdm(diff_functions):\n",
    "\n",
    "    clf = RFFPipelineFunction(\n",
    "        hyper_params={'max_iter': 500}, kern_function=hp[0], add_bias_after=hp[1]\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    clf.fit(x_train_, y_train_)\n",
    "    end = time.time()\n",
    "\n",
    "    pred_test = clf.predict(x_test)\n",
    "    ac_func.append(accuracy_score(y_test, pred_test))\n",
    "    time_func.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "u69vcqVOASlo",
    "outputId": "3c8f21e7-ca66-4001-9839-5a8f9ab767b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(&lt;ufunc 'cos'&gt;, True)</th>\n",
       "      <th>(&lt;ufunc 'cos'&gt;, False)</th>\n",
       "      <th>(&lt;ufunc 'sin'&gt;, True)</th>\n",
       "      <th>(&lt;ufunc 'sin'&gt;, False)</th>\n",
       "      <th>(&lt;ufunc 'exp'&gt;, True)</th>\n",
       "      <th>(&lt;ufunc 'exp'&gt;, False)</th>\n",
       "      <th>(&lt;ufunc 'sign'&gt;, True)</th>\n",
       "      <th>(&lt;ufunc 'sign'&gt;, False)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.861900</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>0.869100</td>\n",
       "      <td>0.861100</td>\n",
       "      <td>0.855500</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.811700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>199.249507</td>\n",
       "      <td>198.575819</td>\n",
       "      <td>199.423517</td>\n",
       "      <td>197.306765</td>\n",
       "      <td>197.482533</td>\n",
       "      <td>201.127019</td>\n",
       "      <td>200.896813</td>\n",
       "      <td>197.962572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          (<ufunc 'cos'>, True)  ...  (<ufunc 'sign'>, False)\n",
       "Accuracy               0.861900  ...                 0.811700\n",
       "Time                 199.249507  ...               197.962572\n",
       "\n",
       "[2 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_names = ['Accuracy', 'Time']\n",
    "res_func = pd.DataFrame([ac_func, time_func], columns=diff_functions)\n",
    "res_func.index = index_names\n",
    "res_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти же результаты ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "xAmbpPgipcah"
   },
   "outputs": [],
   "source": [
    "# Изначально добавляется смещение внутри функции\n",
    "\n",
    "# Код для генерации названия колонок\n",
    "add_bias_after_names = ['Bias outside', 'Bias inside']\n",
    "function_names = []\n",
    "for f in functions:\n",
    "    srt_name = str(f).split(' ')[1][1:4]\n",
    "    if srt_name == 'sig':\n",
    "        function_names.append(str(f).split(' ')[1][1:5])\n",
    "    else:\n",
    "        function_names.append(srt_name)\n",
    "\n",
    "col_names = [i for i in product(function_names, add_bias_after_names)]\n",
    "\n",
    "index_names = ['Accuracy', 'Time']\n",
    "res_func = pd.DataFrame([ac_func, time_func], columns=col_names)\n",
    "res_func.index = index_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "O8vPEkZoWIuK",
    "outputId": "492ddcc1-1140-4f10-81f4-94557b05d25c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(cos, Bias outside)</th>\n",
       "      <td>0.8619</td>\n",
       "      <td>199.249507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(cos, Bias inside)</th>\n",
       "      <td>0.8667</td>\n",
       "      <td>198.575819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sin, Bias outside)</th>\n",
       "      <td>0.8519</td>\n",
       "      <td>199.423517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sin, Bias inside)</th>\n",
       "      <td>0.8691</td>\n",
       "      <td>197.306765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(exp, Bias outside)</th>\n",
       "      <td>0.8611</td>\n",
       "      <td>197.482533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(exp, Bias inside)</th>\n",
       "      <td>0.8555</td>\n",
       "      <td>201.127019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sign, Bias outside)</th>\n",
       "      <td>0.8123</td>\n",
       "      <td>200.896813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sign, Bias inside)</th>\n",
       "      <td>0.8117</td>\n",
       "      <td>197.962572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy        Time\n",
       "(cos, Bias outside)     0.8619  199.249507\n",
       "(cos, Bias inside)      0.8667  198.575819\n",
       "(sin, Bias outside)     0.8519  199.423517\n",
       "(sin, Bias inside)      0.8691  197.306765\n",
       "(exp, Bias outside)     0.8611  197.482533\n",
       "(exp, Bias inside)      0.8555  201.127019\n",
       "(sign, Bias outside)    0.8123  200.896813\n",
       "(sign, Bias inside)     0.8117  197.962572"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_func.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g17VeCu5WIU4"
   },
   "source": [
    "Таким образом, видно, что добавление смещения внутри функции (**bias inside**)\n",
    "\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "\n",
    "или после применения функции (**bias outside**)\n",
    "\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x) + b_1,\n",
    "\\dots,\n",
    "\\cos (w_n^T x) + b_n\n",
    "),$$\n",
    "\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$\n",
    "\n",
    "не сильно влияет на качество алгоритма.\n",
    "В некоторых случаях (cos, sin) лучше добавлять смещение внутри функции, а в других случаях (exp, sign) лучше добавлять его после.\n",
    "\n",
    "С разными типами функций качество незначительно меняется. У синуса доля верных ответов чуть выше по сравнению с косинусом.\n",
    "У экспоненты и знака от признаков качество получилось ниже, чем у тригонометрических функций. Все алгоритмы обучались примерно одинаковое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdZ1M_y6YOdl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_ml2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
